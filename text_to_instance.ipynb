{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"\n",
    "    background-color: #f7f7f7;\n",
    "    background-image: url('data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+CjxzdmcKICAgd2lkdGg9IjcyIgogICBoZWlnaHQ9IjczIgogICB2aWV3Qm94PSIwIDAgNzIgNzMiCiAgIGZpbGw9Im5vbmUiCiAgIHZlcnNpb249IjEuMSIKICAgaWQ9InN2ZzEzMTkiCiAgIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIKICAgeG1sbnM6c3ZnPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CiAgPGRlZnMKICAgICBpZD0iZGVmczEzMjMiIC8+CiAgPHBhdGgKICAgICBkPSJNIC0wLjQ5OTk4NSwxNDUgQyAzOS41MzMsMTQ1IDcyLDExMi41MzIgNzIsNzIuNSA3MiwzMi40Njc4IDM5LjUzMywwIC0wLjQ5OTk4NSwwIC00MC41MzI5LDAgLTczLDMyLjQ2NzggLTczLDcyLjUgYyAwLDQwLjAzMiAzMi40NjcxLDcyLjUgNzIuNTAwMDE1LDcyLjUgeiIKICAgICBmaWxsPSIjMDA4YTY3IgogICAgIGZpbGwtb3BhY2l0eT0iMC4yNSIKICAgICBpZD0icGF0aDEzMTciIC8+Cjwvc3ZnPgo='), url('data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiIHN0YW5kYWxvbmU9Im5vIj8+CjxzdmcKICAgd2lkdGg9IjIxNyIKICAgaGVpZ2h0PSIyMjMiCiAgIHZpZXdCb3g9IjAgMCAyMTcgMjIzIgogICBmaWxsPSJub25lIgogICB2ZXJzaW9uPSIxLjEiCiAgIGlkPSJzdmcxMTA3IgogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciCiAgIHhtbG5zOnN2Zz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogIDxkZWZzCiAgICAgaWQ9ImRlZnMxMTExIiAvPgogIDxwYXRoCiAgICAgZD0ibSAyMi4wNDIsNDUuMDEwOSBjIDIxLjM2MjUsMjEuMjc1NyA1NS45NzYsMjEuMjc1NyA3Ny41MTkyLDAgQyAxMTkuNTU4LDI1LjA4IDE1MS41MDIsMjMuNzM1MiAxNzIuODY0LDQxLjM3OCBjIDEuMzQ1LDEuNTI1NCAyLjY5LDMuMjUxNiA0LjIzNiw0Ljc5NzEgMjEuMzYzLDIxLjI3NTYgMjEuMzYzLDU1Ljc5ODkgMCw3Ny4yNTQ5IC0yMS4zNjIsMjEuMjc2IC0yMS4zNjIsNTUuNzk4IDAsNzcuMjU1IDIxLjM2MywyMS40NTYgNTUuOTc2LDIxLjI3NSA3Ny41MiwwIDIxLjU0MywtMjEuMjc2IDIxLjM2MiwtNTUuNzk5IDAsLTc3LjI1NSAtMjEuMzYzLC0yMS4yNzYgLTIxLjM2MywtNTUuNzk4NiAwLC03Ny4yNTQ5IDEyLjY4OSwtMTIuNjQ1IDE3Ljg4OSwtMzAuMTA3MSAxNS4zOTksLTQ2LjU4NTc2IC0xLjU0NiwtMTEuNTAwOTQgLTYuNzI2LC0yMi44MjExNCAtMTUuNTgsLTMxLjYzMjU0IC0yMS4zNjMsLTIxLjI3NTYgLTU1Ljk3NiwtMjEuMjc1NiAtNzcuNTE5LDAgLTIxLjM2MywyMS4yNzU3IC01NS45NzYsMjEuMjc1NyAtNzcuNTE5NCwwIC0yMS4zNjI1LC0yMS4yNzU2IC01NS45NzYxLC0yMS4yNzU2IC03Ny41MTkyLDAgQyAwLjY3OTU2NSwtMTAuNzg3NiAwLjY3OTU5NiwyMy43MzUyIDIyLjA0Miw0NS4wMTA5IFoiCiAgICAgZmlsbD0iIzJhNGNkZiIKICAgICBzdHJva2U9IiMyYTRjZGYiCiAgICAgc3Ryb2tlLXdpZHRoPSIxMiIKICAgICBzdHJva2UtbWl0ZXJsaW1pdD0iMTAiCiAgICAgaWQ9InBhdGgxMTA1IiAvPgogIDxwYXRoCiAgICAgZD0ibSA1MS45OTUyMTIsMjIyLjczMDEzIGMgMjguMzU5MSwwIDUxLjM1ODM5OCwtMjIuOTk5OSA1MS4zNTgzOTgsLTUxLjM1ODQgMCwtMjguMzU4NiAtMjIuOTk5Mjk4LC01MS4zNTg1OSAtNTEuMzU4Mzk4LC01MS4zNTg1OSAtMjguMzU5MSwwIC01MS4zNTg2MDIsMjIuOTk5OTkgLTUxLjM1ODYwMiw1MS4zNTg1OSAwLDI4LjM1ODUgMjIuOTk5NTAyLDUxLjM1ODQgNTEuMzU4NjAyLDUxLjM1ODQgeiIKICAgICBmaWxsPSIjMTkyZTg2IgogICAgIGZpbGwtb3BhY2l0eT0iMC4zNSIKICAgICBpZD0icGF0aDE5MzciIC8+Cjwvc3ZnPgo=') ;\n",
    "    background-position: left bottom, right top;\n",
    "    background-repeat: no-repeat,  no-repeat;\n",
    "    background-size: auto 60px, auto 160px;\n",
    "    border-radius: 5px;\n",
    "    box-shadow: 0px 3px 1px -2px rgba(0, 0, 0, 0.2), 0px 2px 2px 0px rgba(0, 0, 0, 0.14), 0px 1px 5px 0px rgba(0,0,0,.12);\">\n",
    "\n",
    "<h1 style=\"\n",
    "    color: #2a4cdf;\n",
    "    font-style: normal;\n",
    "    font-size: 2.25rem;\n",
    "    line-height: 1.4em;\n",
    "    font-weight: 600;\n",
    "    padding: 30px 200px 0px 30px;\"> \n",
    "        Example of using OllamaFunctions with Llama3 to fill a schema from text.</h1>\n",
    "\n",
    "<p style=\"\n",
    "    line-height: 1.4em;\n",
    "    padding: 30px 200px 0px 30px;\">\n",
    "        This notebook demonstrates how to use <a href=\"https://python.langchain.com/v0.1/docs/integrations/chat/ollama_functions/\" target=\"_blank\">OllamaFunctions from langchain</a> with <a href=\"https://github.com/meta-llama/llama3\" target=\"_blank\">LLama3 LLM</a> to fill a json-schema defined as a pydantic model from text. The example uses a text previously transcribed from audio emulating recording an experiment in the lab where the sicentist cannot type. The text is then used to fill a schema that can be used to store the data in a database or in your favorite research data management solution.  \n",
    "</p>\n",
    "\n",
    "<p style=\"font-size: 1.25em; font-style: italic; padding: 5px 200px 30px 30px;\">\n",
    "    Hampus Näsström, Julia Schumann and Michael Götte.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using OllamaFunctions to fill a schema from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import List\n",
    "\n",
    "model = OllamaFunctions(model=\"llama3:70b\", base_url='http://172.28.105.30/backend', format='json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Solution(BaseModel):\n",
    "    temperature: float = Field(\n",
    "        ..., description=\"The temperature of the solution creation\")\n",
    "    atmosphere: str = Field(\n",
    "        ..., description=\"The atmosphere of the solution creation\")\n",
    "    method: str = Field(\n",
    "        ..., description=\"The method of the solution creation\")\n",
    "    time: float = Field(\n",
    "        ..., description=\"The time needed for the solution creation\")\n",
    "    solutes: List[str] = Field(\n",
    "        ..., description=\"The solutes used in the solution\")\n",
    "    solute_masses: List[float] = Field(\n",
    "        ..., description=\"The masses in miligramm of the solutes used in the solution\")\n",
    "    solvents: List[str] = Field(\n",
    "        ..., description=\"The solvents used in the solution\")\n",
    "    solvent_volumes: List[float] = Field(\n",
    "        ..., description=\"The volumes in mililiter of the solvents used in the solution\")\n",
    "\n",
    "class Scaling(BaseModel):\n",
    "    powder: str = Field(\n",
    "        ..., description=\"The name of the powder to be scaled\")\n",
    "    mass: float = Field(\n",
    "        ..., description=\"The scaled mass of the powder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_msg = \"Please create a solution of 2mg lead iodide as a solute and 100 ml ethanol as a solvent. The solution is produced at 25 degree celsius stirred for 15 minutes.\"\n",
    "scaling_msg = \"Please create a scaling entry for 5mg of lead iodide.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You should extract the information from the following text and create a structured output.\n",
    "If information is missing you should fill it with null.\n",
    "If something is unclear you should ask for clarification.\n",
    "\n",
    "Human: {question}\n",
    "AI:\n",
    "\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"solution_preparation\",\n",
    "            \"description\": \"Schema for solution preparation\",\n",
    "            \"parameters\": Solution.schema(),\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"powder_scaling\",\n",
    "            \"description\": \"Schema for powder scaling\",\n",
    "            \"parameters\": Scaling.schema(),\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_tools = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking: \"Please create a solution of 2mg lead iodide as a solute and 100 ml ethanol as a solvent. The solution is produced at 25 degree celsius stirred for 15 minutes.\"\n",
      "Schema used: solution_preparation\n",
      "Created instance:\n",
      "{\n",
      "  \"temperature\": 25,\n",
      "  \"atmosphere\": null,\n",
      "  \"method\": \"stirred\",\n",
      "  \"time\": 15,\n",
      "  \"solutes\": [\n",
      "    \"lead iodide\"\n",
      "  ],\n",
      "  \"solute_masses\": [\n",
      "    2\n",
      "  ],\n",
      "  \"solvents\": [\n",
      "    \"ethanol\"\n",
      "  ],\n",
      "  \"solvent_volumes\": [\n",
      "    100\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f'Asking: \"{solution_msg}\"')\n",
    "response_solution = chain_with_tools.invoke(solution_msg)\n",
    "schema = response_solution.additional_kwargs['function_call']['name']\n",
    "instance = json.loads(response_solution.additional_kwargs['function_call']['arguments'])\n",
    "print(f'Schema used: {schema}')\n",
    "print('Created instance:')\n",
    "print(json.dumps(instance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asking: \"Please create a scaling entry for 5mg of lead iodide.\"\n",
      "Schema used: powder_scaling\n",
      "Created instance:\n",
      "{\n",
      "  \"powder\": \"lead iodide\",\n",
      "  \"mass\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(f'Asking: \"{scaling_msg}\"')\n",
    "response_scaling = chain_with_tools.invoke(scaling_msg)\n",
    "schema = response_scaling.additional_kwargs['function_call']['name']\n",
    "instance = json.loads(response_scaling.additional_kwargs['function_call']['arguments'])\n",
    "print(f'Schema used: {schema}')\n",
    "print('Created instance:')\n",
    "print(json.dumps(instance, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
